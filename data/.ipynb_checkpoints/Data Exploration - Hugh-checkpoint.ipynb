{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Visualization - Taxi Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data (Yellow Cab, 2013): http://www.andresmh.com/nyctaxitrips/\n",
    "\n",
    "* Data (Yellow cab, June 2015): http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml\n",
    "\n",
    "* *Incredible* visualization: http://nyctaxi.herokuapp.com/\n",
    "\n",
    "**Privacy Concerns**\n",
    "\n",
    "* Privacy concerns with the dataset: http://research.neustar.biz/2014/09/15/riding-with-the-stars-passenger-privacy-in-the-nyc-taxicab-dataset/\n",
    "\n",
    "* Locating Muslim cab drivers: http://mashable.com/2015/01/28/redditor-muslim-cab-drivers/#PJCrpyV6tPqY\n",
    "\n",
    "**Uber Disruption**\n",
    "\n",
    "* October 13, 2015: http://fivethirtyeight.com/features/uber-is-taking-millions-of-manhattan-rides-away-from-taxis/\n",
    "\n",
    "* August 10, 2015: http://fivethirtyeight.com/features/uber-is-serving-new-yorks-outer-boroughs-more-than-taxis-are/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainstorming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Uber data, we could look at change in pickups between taxis and Uber. 538 already did this (see 10/13/15 article).\n",
    "\n",
    "So taxi cab drivers *are* full-time employees. Cite that. However, Uber drivers are treated as independent contractors. This changes their compensation package, tax structure, and most importantly benefits (i.e. no health care)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df2015 = pd.read_csv('raw_data/yellow_tripdata_2015-06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2013trip = pd.read_csv('raw_data/sample_trip.csv')\n",
    "df2013fare = pd.read_csv('raw_data/sample_fare.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ssize = 1000000\n",
    "#df2013trip = pd.read_csv('raw_data/trip_data_1.csv', nrows=ssize)\n",
    "#df2013fare = pd.read_csv('raw_data/trip_fare_1.csv', nrows=ssize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2013trip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2013fare.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we merge and clean the datasets. The column names are slightly different. And information about the trip and fare are split into separate data chunks. They can be merged into a single dataframe based on columns like medallion - a hash value that represents a unique taxi driver.\n",
    "\n",
    "See the difference in column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df2013trip.columns\n",
    "print df2013fare.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2013fare.rename(columns={\n",
    "        ' hack_license' : 'hack_license',\n",
    "        ' vendor_id' : 'vendor_id',\n",
    "        ' pickup_datetime' : 'pickup_datetime',\n",
    "        ' payment_type' : 'payment_type',\n",
    "        ' fare_amount' : 'fare_amount',\n",
    "        ' surcharge' : 'surcharge',\n",
    "        ' mta_tax' : 'mta_tax',\n",
    "        ' tip_amount' : 'tip_amount',\n",
    "        ' tolls_amount' : 'tolls_amount',\n",
    "        ' total_amount' : 'total_amount'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we merge our two data sets containing trip and fare information for the same cab trips into a single dataframe called `merged2013df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged2013dffull = pd.merge(df2013trip, df2013fare, on=['medallion', 'hack_license', 'vendor_id', 'pickup_datetime'], how='inner')\n",
    "\n",
    "merged2013dffull.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we eliminate the row with missing latitude or longitude information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged2013dffull = merged2013dffull[merged2013dffull.pickup_latitude.between(40.65,40.85)]\n",
    "merged2013dffull = merged2013dffull[merged2013dffull.pickup_longitude.between(-74.025,-73.85)]\n",
    "merged2013dffull = merged2013dffull[merged2013dffull.dropoff_latitude.between(40.65,40.85)]\n",
    "merged2013dffull = merged2013dffull[merged2013dffull.dropoff_longitude.between(-74.025,-73.85)]\n",
    "merged2013dffull = merged2013dffull.reset_index(drop=True)\n",
    "merged2013dffull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove incomplete trips\n",
    "merged2013dffull = merged2013dffull[merged2013dffull.trip_distance > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we add a column called `tip_amount_normalized` that calculates the tip as a percentage of the total cost of the trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged2013dffull['tip_amount_normalized'] = merged2013dffull.tip_amount/merged2013dffull.fare_amount\n",
    "merged2013dffull.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add another column to create a numerical representation for the types of payment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "payment_types = list(merged2013dffull.payment_type.unique())\n",
    "payment_dict = dict(zip(payment_types, map(lambda x: payment_types.index(x), payment_types)))\n",
    "\n",
    "# Create payment index\n",
    "merged2013dffull['payment_idx'] = merged2013dffull.payment_type.apply(lambda x: payment_dict[x])\n",
    "merged2013dffull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add column that replaces rate codes with string names\n",
    "\n",
    "rate_codes = {\n",
    "    1: 'Standard Rate',\n",
    "    2: 'JFK',\n",
    "    3: 'Newark',\n",
    "    4: 'Nassau or Westchester',\n",
    "    5: 'Negotiated fare',\n",
    "    6: 'Group Ride'\n",
    "}\n",
    "\n",
    "merged2013dffull['rate_code_name'] = merged2013dffull['rate_code'].map(lambda x: rate_codes[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For our regression, we only care about standard rate fares, since they are likely more correlated with tip amount & distance\n",
    "merged2013dffull = merged2013dffull[merged2013dffull['rate_code'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Eliminate high tip outliers\n",
    "merged2013dffull = merged2013dffull[merged2013dffull.tip_amount_normalized < 1.]\n",
    "merged2013dffull = merged2013dffull.reset_index(drop=True)\n",
    "print merged2013dffull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove rare payment types\n",
    "merged2013dffull = merged2013dffull[merged2013dffull.payment_type != 'UNK']\n",
    "merged2013dffull = merged2013dffull[merged2013dffull.payment_type != 'DIS']\n",
    "merged2013dffull = merged2013dffull[merged2013dffull.payment_type != 'NOC']\n",
    "merged2013dffull = merged2013dffull.reset_index(drop=True)\n",
    "print merged2013dffull.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert pickup and dropoff to date objects\n",
    "\n",
    "merged2013dffull['pickup_datetime'] = pd.to_datetime(merged2013dffull['pickup_datetime'])\n",
    "merged2013dffull['dropoff_datetime'] = pd.to_datetime(merged2013dffull['dropoff_datetime'])\n",
    "merged2013dffull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seconds_since_midnight(d):\n",
    "    ddelta = (d - d.replace(hour=0, minute=0, second=0, microsecond=0))\n",
    "    return ddelta.total_seconds()\n",
    "\n",
    "merged2013dffull['secs_since_midnight'] = merged2013dffull.pickup_datetime.apply(seconds_since_midnight)\n",
    "merged2013dffull = merged2013dffull[merged2013dffull['trip_time_in_secs'] > 0]\n",
    "merged2013dffull['hours_since_midnight'] = merged2013dffull.secs_since_midnight/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(merged2013dffull.payment_idx, bins=np.arange(0,4,1))\n",
    "# plt.xticks([0, 1, 2])\n",
    "# plt.axhline(0, color='k')\n",
    "# plt.title('Payment Counts')\n",
    "# plt.ylabel('Number of Trips')\n",
    "# plt.xlabel('Pa')\n",
    "payment_counts = merged2013dffull.groupby(['payment_type'])['medallion'].count()\n",
    "#merged2013df.groupby(['hours_since_midnight'])['tip_amount_normalized'].mean()\n",
    "#merged2013df.groupby('hours_since_midnight')['tip_amount_normalized'].head()\n",
    "ax = payment_counts.plot(kind='bar', x='payment_type', y='medallion', alpha=.6)\n",
    "ax.set_xlabel(\"Payment Type\")\n",
    "ax.set_ylabel(\"Number of Rides\")\n",
    "ax.grid(False)\n",
    "ax.set_title('Number of Rides Paying Cash vs. Credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So what is the tip distribution like?\n",
    "# merged2013df[merged2013df.tip_amount != 0].tip_amount_normalized.describe()\n",
    "#We only want credit card transactions\n",
    "merged2013df = merged2013dffull[merged2013dffull['payment_type'] == 'CRD']\n",
    "print merged2013df.shape\n",
    "\n",
    "#merged2013df.payment_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So what is the tip distribution like?\n",
    "merged2013df.tip_amount_normalized.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add a column to convert our pickup times to number of seconds since midnight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those that tip, what percentage of the total fare cost do they tip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged2013df[merged2013df.tip_amount_normalized > 0].tip_amount_normalized.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what percentage of people actually tip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(len(merged2013df[merged2013df.tip_amount > 0])) / float(len(merged2013df.tip_amount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 1: Initial Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a sense of the data we're working with. Using Matplotlib's Basemap, we can see the pickup locations for our data subset. *(Warning: this takes about 5 minutes to run)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = Basemap(projection='merc',llcrnrlat=40.55,urcrnrlat=40.82,\\\n",
    "            llcrnrlon=-74.1, urcrnrlon=-73.82, lat_ts=40.5,resolution='f')\n",
    "m.drawmapboundary(fill_color='#85A6D9')\n",
    "m.drawcoastlines(color='#6D5F47', linewidth=.4)\n",
    "m.drawrivers(color='#6D5F47', linewidth=.4)\n",
    "m.fillcontinents(color='white', lake_color='#85A6D9')\n",
    "\n",
    "for x in range(1, 10000):\n",
    "    m.plot(merged2013df.pickup_longitude[x],merged2013df.pickup_latitude[x],'ro',latlon=True,ms=1,alpha=.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's create a visualization for a single cab driver to see their pickup and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = Basemap(projection='merc',llcrnrlat=40.55,urcrnrlat=40.82,\\\n",
    "            llcrnrlon=-74.1, urcrnrlon=-73.82, lat_ts=40.5,resolution='h')\n",
    "m.drawmapboundary(fill_color='#85A6D9')\n",
    "m.drawcoastlines(color='#6D5F47', linewidth=.4)\n",
    "m.drawrivers(color='#6D5F47', linewidth=.4)\n",
    "m.fillcontinents(color='white', lake_color='#85A6D9')\n",
    "\n",
    "ex_cab = merged2013df[merged2013df.medallion == '000318C2E3E6381580E5C99910A60668'].reset_index(drop=True)\n",
    "mx_pickup, my_pickup = list(ex_cab.pickup_longitude),list(ex_cab.pickup_latitude)\n",
    "mx_dropoff, my_dropoff = list(ex_cab.dropoff_longitude),list(ex_cab.dropoff_latitude)\n",
    "assert len(mx_pickup) == len(my_pickup) == len(mx_dropoff) == len(my_dropoff)\n",
    "\n",
    "for i in range(len(mx_pickup)):\n",
    "    m.plot(mx_pickup[i], my_pickup[i],'ro',latlon=True,ms=3,alpha=1)\n",
    "    m.plot(mx_dropoff[i], my_dropoff[i],'go',latlon=True,ms=3,alpha=1)\n",
    "\n",
    "plt.title(\"Pickup and Dropoff Points for Cab #000318C2E3E6381580E5C99910A60668\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to be able to convert our pairs of coordinates from the pickup and dropoff points into map-like information about the location - like an address. In order to do this, we take advantage of the Google Maps Geocoding API. Our use is limited by the rate query: 10 requests per second, 2500 free requests per 24 hours.\n",
    "\n",
    "In order to take advantage of it, go to the following site and register your IP address: https://developers.google.com/maps/documentation/geocoding/get-api-key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've registered, enter your API key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geocoding_api_key = 'AIzaSyCDqqN3Ky2lnba6p23VAKzIgrvsTwZwzM0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `rev_geocode` takes a latitude and longitude pair, and returns the JSON output from the Google Maps Geocoding API, which contains detailed geographical information about the coordinate pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def rev_geocode(latitude, longitude):\n",
    "    API_str = 'https://maps.googleapis.com/maps/api/geocode/json?latlng=' \\\n",
    "    + str(latitude) + ',' + str(longitude) + '&key=' + geocoding_api_key\n",
    "    return requests.get(API_str).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rev_geocode(-73.978165, 40.757977)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create some histograms to examine the frequency of the important columns in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "hist_columns = ['passenger_count','trip_time_in_secs', 'trip_distance','fare_amount', \\\n",
    "                'tip_amount', 'total_amount', 'tip_amount_normalized', 'secs_since_midnight']\n",
    "fig, ax_lst = plt.subplots(4, 2)\n",
    "axes = itertools.chain.from_iterable(ax_lst)\n",
    "\n",
    "quantiles = merged2013df.quantile(.90)\n",
    "for column in hist_columns:\n",
    "    merged2013df = merged2013df[merged2013df[column] <= quantiles[column]]\n",
    "\n",
    "for column in hist_columns:\n",
    "    ax = next(axes)\n",
    "    ax.hist(merged2013df[column].values)\n",
    "    #ax.set_title(\"Histogram\")\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The (erratic) art of tipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `merged2013df` as our base dataset for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged2013df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a dictionary called `tipclassifiers` that contains some basic information about the tipping habits of people. We figured out the amount of tip and percentage with respect to the total fare for all riders and riders that actually give a tip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tipstats = {}\n",
    "tipstats['tip'] = merged2013df[merged2013df.tip_amount > 0]\n",
    "tipstats['no_tip'] = merged2013df[merged2013df.tip_amount == 0]\n",
    "tipstats['tip_perc'] = float(len(merged2013df[merged2013df.tip_amount > 0])) / float(len(merged2013df))\n",
    "tipstats['tip_mean'] = merged2013df.tip_amount.mean()\n",
    "tipstats['pos_tip_mean'] = tipstats['tip'].tip_amount.mean()\n",
    "tipstats['tip_norm_mean'] = merged2013df.tip_amount_normalized.mean()\n",
    "tipstats['pos_tip_norm_mean'] = tipstats['tip'].tip_amount_normalized.mean()\n",
    "print \"Percentage of riders that tip: %.3f%%\" % (tipstats['tip_perc'] * 100)\n",
    "print \"Tip amounts (all riders, riders that tip) $%.2f, $%.2f\" % (tipstats['tip_mean'], tipstats['pos_tip_mean'])\n",
    "print \"Tip percentages (all riders, riders that tip): %.3f%%, %.3f%%\" % (tipstats['tip_norm_mean'] * 100, tipstats['pos_tip_norm_mean'] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tipping based on fare amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting question we can ask is whether we can predict whether a rider will tip on a cab trip. Intuitively, we might imagine that people tend to tip based on a variety of traits. Perhaps a banker on Wall Street or someone with a relatively high income is more likely to be generous with a tip. It's plausible that riders at night are more likely to tip because they are out for entertainment or on dates, or maybe more daytime riders tip because many professionals bill the taxi fare to the company they work rather than their own credit and are therefore more likely to be generous.\n",
    "\n",
    "In this section we'll examine what correlations exist (if any) between a rider's decision to tip and other factors related to the cab ride.\n",
    "\n",
    "First, we'll create a regression that examines whether fare amount is correlated with the decision to tip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Logistic regression** is a probabilistic model that links observed binary data to a set of features.\n",
    "\n",
    "Suppose that we have a set of binary (that is, taking the values 0 or 1) observations $Y_1,\\cdots,Y_n$, and for each observation $Y_i$ we have a vector of features $X_i$. The logistic regression model assumes that there is some set of **weights**, **coefficients**, or **parameters** $\\Theta$, one for each feature, so that the data were generated by flipping a weighted coin whose probability of giving a 1 is given by the following equation:\n",
    "\n",
    "$$\n",
    "P(Y_i = 1) = \\sigma(\\sum \\Theta_i X_i),\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is the *sigmoid* (or logit) function\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{e^x}{1+e^x}.\n",
    "$$\n",
    "\n",
    "When we *fit* a logistic regression model, we determine values for each $\\Theta_i$ that allows the model to best fit the *training data* we have observed. Once we do this, we can use these coefficients to make predictions about data we have not yet observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So let's create our known observations outcomes - that is, our X and y for the fare amount and whether the riders chose to tip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X - fare amount\n",
    "X = merged2013df.fare_amount.values.reshape(len(merged2013df), 1)\n",
    "\n",
    "# y - decision to tip (binary feature)\n",
    "y = merged2013df.tip_amount.apply(lambda x: 1 if x > 0 else 0).values.ravel()\n",
    "\n",
    "# create a dataframe\n",
    "logit_data = pd.DataFrame(zip(X,y))\n",
    "logit_data.columns = ['fare', 'tipped']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and run logistic regression on the entire data set, and see how accurate it is!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "logit_model = LogisticRegression()\n",
    "logit_model.fit(X, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "logit_model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "54% accuracy doesn't seem great, but what's the null error rate? That is, if we predicted a rider won't tip every time, how often would we be wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y.mean() is the percentage that tip\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 49% of riders gave no tip, which means that you could obtain 51% accuracy by always predicting \"yes\". So we're doing better than the positive error rate, but not in a meaningful way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly plot the fares against the decision to tip to visualize the findings from the our regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.xlim([0, 300])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.title(\"Fare amount vs. Decision to tip\")\n",
    "plt.xlabel(\"Fare ($)\")\n",
    "plt.ylabel(\"Tipped?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the regression score suggested and the visualization demonstrates, the correlation is virtually non-existent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Finding other correlations with tip amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also consider other potential factors that influence how much riders tip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = ols('tip_amount ~ fare_amount + passenger_count + trip_time_in_secs + payment_idx + pickup_latitude + pickup_longitude + secs_since_midnight', merged2013df).fit()\n",
    "print m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use $R^2$ as a measure of how well data fits our linear model. It represents a ratio of the explained variance to the total variance. A value of 1 means the data fits perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An $R^2$ value of $0.57$ and it implies that 57% of the variability between the two variables have been accounted for and the remaining 43% of the variability is still unaccounted for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Logistic regression with payment type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "While noodling about what tips could tell us, we realized that many of the taxi drivers don't report tips. This is either because people using cash are less likely to tip, or because the tips are going unreported so that the cab drivers don't have to take a loss in taxes on the tips. Since all of us are mind-numbingly cynical in nature, we prefer to believe that it's the latter. Is there any way that we could think to estimate how much money goes under the table in taxis in NYC?\n",
    "\n",
    "Indeed, if we use a linear regression model with some of the continuous features such as trip length and cost, we hope to be able to fit a model to predict the tip that might be expected to be given for a certain type of taxi ride in NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Try comparing payment type against tip amount (based on promising results from part 1.2)\n",
    "X = merged2013df.tip_amount.values.reshape(len(merged2013df), 1)\n",
    "y = merged2013df.payment_idx.values.ravel()\n",
    "\n",
    "# Create the model\n",
    "logit_model = LogisticRegression()\n",
    "logit_model.fit(X, y)\n",
    "\n",
    "# Predict on the training set\n",
    "results_y = logit_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what is the mean accuracy on the given test data and labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, results_y)\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that our initial hypothesis is right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"CASH: $%.5f\" % merged2013df[merged2013df.payment_idx == 0].tip_amount.mean()\n",
    "print \"CREDIT: $%.5f\" % merged2013df[merged2013df.payment_idx == 1].tip_amount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tipstats['pos_tip_norm_mean']*(tipstats['no_tip'].fare_amount.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Predicting Unreported Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous parts of this ipython notebook, we found that almost nobody who paid in cash had their tips recorded. This is likely because taxi drivers don't want to lose money to taxes that go along with reporting tips. We'd like to find out just how much money has gone unreported in our dataset.\n",
    "\n",
    "Above we created a very rough baseline by taking the average tip reported for customers who paid with credit, and multiplied it by the total amount spent by customers who paid with cash in the entire dataset. The assumption behind this baseline is that people who pay in cash don't tip fundamentally differently from those who pay with credit. This seems like a fair assumption to make. It's highly unlikely that people who pay cash simply don't tip.\n",
    "\n",
    "We'll employ a more sophisticated method to try to predict unreported tips using kNN classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Classification Applied to tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN is a classification method that is used to predict to which class a certain data point belongs. It makes sense to think about tips in terms of classes because we think about tips fundamentally in terms of classes anyway. For example, we may think that a 10-15% tip is a reasonable tip (perhaps a bit on the low side), whereas a tip that is between 15-25% is a very good tip. Anything above that is seen as a very large tip.\n",
    "\n",
    "The first step in this process is to create a classifier that identifies to which class a tip belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# make a copy of the df to use in machine learning classification\n",
    "# credit df and cash df\n",
    "cash_df = merged2013df[merged2013df.payment_type == 'CSH']\n",
    "crd_df = merged2013df[merged2013df.payment_type == 'CRD']\n",
    "\n",
    "# remove outlier tips above 40%\n",
    "small_crd_df = crd_df[crd_df.tip_amount_normalized <= .4]\n",
    "\n",
    "# classify tips into buckets based on 5% intervals\n",
    "small_crd_df['tip_class'] = small_crd_df.tip_amount_normalized.apply(lambda x: math.floor(x*100/5.0))\n",
    "\n",
    "cols = ['passenger_count','trip_time_in_secs','trip_distance','fare_amount','secs_since_midnight','pickup_latitude','pickup_longitude']\n",
    "\n",
    "# remove outliers from classifiers for plotting\n",
    "small_crd_df_plot = small_crd_df[small_crd_df['trip_time_in_secs'] <= 4000]\n",
    "small_crd_df_plot = small_crd_df_plot[small_crd_df_plot['trip_distance'] <= 25]\n",
    "small_crd_df_plot = small_crd_df_plot[small_crd_df_plot['fare_amount'] <= 75]\n",
    "small_crd_df_plot = small_crd_df_plot[small_crd_df_plot['pickup_longitude'] <= -73.5]\n",
    "small_crd_df_plot = small_crd_df_plot[small_crd_df_plot['pickup_longitude'] >= -74.2]\n",
    "small_crd_df_plot = small_crd_df_plot[small_crd_df_plot['pickup_latitude'] <= 41]\n",
    "small_crd_df_plot = small_crd_df_plot[small_crd_df_plot['pickup_latitude'] >= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_crd_df[['tip_amount_normalized','tip_class']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips are now sorted into buckets on a 5% interval. This will hopefully allow us to predict which bucket cash tips would have fallen into had they been recorded based on the other features of the ride. Essentially, we'll find out which rides that were paid for in credit are closest to any given cash ride point (in Euclidean space) and use those to classify the credit point. This requires us the split the data into training and test sets.\n",
    "\n",
    "Before we actually get into doing the kNN classifications, let's examine some of the different classifiers we could use. Ideally we'd like to used classifiers which are clear differentiators between tipping buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_crd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the subplots figure\n",
    "fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(30,50), tight_layout=True)\n",
    "\n",
    "for a, c in zip(ax.ravel(), cols):\n",
    "\n",
    "    # different tip classes\n",
    "    tc_0 = small_crd_df_plot.loc[small_crd_df_plot['tip_class'] == 0][c]\n",
    "    tc_1 = small_crd_df_plot.loc[small_crd_df_plot['tip_class'] == 1][c]\n",
    "    tc_2 = small_crd_df_plot.loc[small_crd_df_plot['tip_class'] == 2][c]\n",
    "    tc_3 = small_crd_df_plot.loc[small_crd_df_plot['tip_class'] == 3][c]\n",
    "    tc_4 = small_crd_df_plot.loc[small_crd_df_plot['tip_class'] == 4][c]\n",
    "    tc_5 = small_crd_df_plot.loc[small_crd_df_plot['tip_class'] == 5][c]\n",
    "    tc_6 = small_crd_df_plot.loc[small_crd_df_plot['tip_class'] == 6][c]\n",
    "\n",
    "    with sns.color_palette('muted'):\n",
    "    # plot data\n",
    "        sns.kdeplot(tc_0, color='blue', label='Tip Class 0', ax=a, shade=True)\n",
    "        sns.kdeplot(tc_1, color='red', label='Tip Class 1', ax=a, shade=True)\n",
    "        sns.kdeplot(tc_2, color='green', label='Tip Class 2', ax=a, shade=True)\n",
    "        sns.kdeplot(tc_3, color='yellow', label='Tip Class 3', ax=a, shade=True)\n",
    "        sns.kdeplot(tc_4, color='purple', label='Tip Class 4', ax=a, shade=True)\n",
    "        sns.kdeplot(tc_5, color='pink', label='Tip Class 5', ax=a, shade=True)\n",
    "        sns.kdeplot(tc_6, color='brown', label='Tip Class 6', ax=a, shade=True)\n",
    "\n",
    "    # plot semantics\n",
    "    a.set_title(c.replace('_',' ').capitalize())\n",
    "    a.set_xlabel('Value')\n",
    "    a.set_ylabel('Density')\n",
    "    a.grid(False)\n",
    "\n",
    "fig.savefig('KDE_kNN.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first glance tells us that none of these classifiers will be great for differentiating between tip classes, since many of them are very similar. It looks as though we'll be able to classify some outlier points relativelly well based on a single classifier, but the vast majority of point will most likely be hard to predict based on the data that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(xrange(small_crd_df.shape[0]), train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(itrain)\n",
    "print len(itest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask=np.ones(small_crd_df.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to normalize the data at some point. There is any easy way to do this for data such as integers and floats that are amenable to normalization using the sklearn module. For now we'll forgo that step.\n",
    "\n",
    "### kNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from  itertools import combinations\n",
    "\n",
    "def combos_with_exclusion(lst, exclude, length):\n",
    "    for combo in combinations((e for e in lst if e != exclude), length):\n",
    "        yield list(combo)\n",
    "\n",
    "cols_new = ['passenger_count','trip_time_in_secs','trip_distance','fare_amount','secs_since_midnight']\n",
    "cols_sig = ['secs_since_midnight','trip_time_in_secs','fare_amount']\n",
    "\n",
    "n_neighbors = [10,50,100,200,500,1000]\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "Xmatrix = small_crd_df[cols_new]\n",
    "Ymatrix = small_crd_df['tip_class']\n",
    "\n",
    "train_X = Xmatrix[mask]\n",
    "test_X = Xmatrix[~mask]\n",
    "\n",
    "train_y = Ymatrix[mask]\n",
    "test_y = Ymatrix[~mask]\n",
    "\n",
    "# scores = {}\n",
    "best_clf = None\n",
    "best_score = -float('inf')\n",
    "for x in np.arange(1,6):\n",
    "    for sublist in combos_with_exclusion(cols_new, None, x):\n",
    "        Xmatrix = small_crd_df[sublist]\n",
    "        Ymatrix = small_crd_df['tip_class']\n",
    "\n",
    "        train_X = Xmatrix[mask]\n",
    "        test_X = Xmatrix[~mask]\n",
    "\n",
    "        train_y = Ymatrix[mask]\n",
    "        test_y = Ymatrix[~mask]\n",
    "        \n",
    "        print sublist\n",
    "        \n",
    "        for weight in weights:\n",
    "            for n in n_neighbors:\n",
    "                clf = neighbors.KNeighborsClassifier(n, weights=weight)\n",
    "                clf.fit(train_X,train_y)\n",
    "                score = clf.score(test_X, test_y)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_clf = clf\n",
    "                    best_sublist = sublist\n",
    "                print score\n",
    "        print\n",
    "        print best_score\n",
    "#                 scores[(weight, n)] = (sublist, clf, clf.score(test_X, test_y))\n",
    "        \n",
    "# best_sublist = []\n",
    "# best_clf = None\n",
    "# best_score = -float('inf')\n",
    "# for sublist,clf,score in scores.values():\n",
    "#     if score > best_score:\n",
    "#         best_sublist = sublist\n",
    "#         best_clf = clf\n",
    "#         best_score = score\n",
    "print 'best_sublist:'\n",
    "print best_sublist\n",
    "print 'best_score:'\n",
    "print best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in np.arange(1,6):\n",
    "    for sublist in combos_with_exclusion(cols_new, None, x):\n",
    "        print sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# best_score_5 = best_score\n",
    "# best_score_2 = best_score\n",
    "print best_score_5\n",
    "print best_score_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from  itertools import combinations\n",
    "\n",
    "def combos_with_exclusion(lst, exclude, length):\n",
    "    for combo in combinations((e for e in lst if e != exclude), length):\n",
    "        yield list(combo)\n",
    "\n",
    "cols_new = ['passenger_count','trip_time_in_secs','trip_distance','fare_amount','secs_since_midnight']\n",
    "cols_sig = ['secs_since_midnight','trip_time_in_secs','fare_amount']\n",
    "\n",
    "n_neighbors = [10,50,100,200,500,1000]\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "Xmatrix = small_crd_df[cols_new]\n",
    "Ymatrix = small_crd_df['tip_amount_normalized']\n",
    "\n",
    "train_X = Xmatrix[mask]\n",
    "test_X = Xmatrix[~mask]\n",
    "\n",
    "train_y = Ymatrix[mask]\n",
    "test_y = Ymatrix[~mask]\n",
    "\n",
    "# scores = {}\n",
    "best_clf = None\n",
    "best_score = -float('inf')\n",
    "for x in np.arange(1,6):\n",
    "    for sublist in combos_with_exclusion(cols_new, None, x):\n",
    "        Xmatrix = small_crd_df[sublist]\n",
    "        Ymatrix = small_crd_df['tip_amount_normalized']\n",
    "\n",
    "        train_X = Xmatrix[mask]\n",
    "        test_X = Xmatrix[~mask]\n",
    "\n",
    "        train_y = Ymatrix[mask]\n",
    "        test_y = Ymatrix[~mask]\n",
    "        \n",
    "        print sublist\n",
    "        \n",
    "        for weight in weights:\n",
    "            for n in n_neighbors:\n",
    "                clf = neighbors.KNeighborsRegressor(n, weights=weight)\n",
    "                clf.fit(train_X,train_y)\n",
    "                score = clf.score(test_X, test_y)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_clf = clf\n",
    "                    best_sublist = sublist\n",
    "                print score\n",
    "        print\n",
    "        print best_score\n",
    "#                 scores[(weight, n)] = (sublist, clf, clf.score(test_X, test_y))\n",
    "        \n",
    "# best_sublist = []\n",
    "# best_clf = None\n",
    "# best_score = -float('inf')\n",
    "# for sublist,clf,score in scores.values():\n",
    "#     if score > best_score:\n",
    "#         best_sublist = sublist\n",
    "#         best_clf = clf\n",
    "#         best_score = score\n",
    "print 'best_sublist:'\n",
    "print best_sublist\n",
    "print 'best_score:'\n",
    "print best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print best_score_5\n",
    "print best_score_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kristen's Code\n",
    "##I CANT WAIT FOR FREEDOMMMMMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_tip = (merged2013dffull[merged2013dffull['tip_amount_normalized'] > 0]).mean()\n",
    "print avg_tip\n",
    "#avg_tip*((merged2013dffull[merged2013dffull.tip_amount == 0]).fare_amount.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove those with extremely high tips\n",
    "low_tips_df = merged2013df[merged2013df['tip_amount_normalized'] < .4]\n",
    "low_tips = low_tips_df['tip_amount_normalized']\n",
    "low_tips.plot(kind='hist', alpha=0.5, bins=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_tips = low_tips_df['tip_amount_normalized']\n",
    "low_tips.plot(kind='hist', alpha=0.5, bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking down the histogram into greater detail, we can see peaks at 0%, 20%, 25% and 30%, the default tip options on the credit card readers in cabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged2013df['hours_since_midnight'] = np.floor(merged2013df['secs_since_midnight']/3600)\n",
    "#small_df = merged2013df[['tip_amount_normalized','hours_since_midnight']]\n",
    "small_df = merged2013df.groupby(['hours_since_midnight'])['tip_amount_normalized'].mean()\n",
    "#merged2013df.groupby(['hours_since_midnight'])['tip_amount_normalized'].mean()\n",
    "#merged2013df.groupby('hours_since_midnight')['tip_amount_normalized'].head()\n",
    "small_df.plot(kind='bar', x='hours_since_midnight', y='tip_amount_normalized')\n",
    "plt.ylim((.175,.2))\n",
    "ax.set_xlabel(\"Hours since Midnight\")\n",
    "ax.set_ylabel(\"Average Tip %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the graph, the largest % tips, on average, occur at night between 9pm-1am."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fare_df = merged2013df.groupby(['hours_since_midnight'])['fare_amount'].sum()\n",
    "#merged2013df.groupby(['hours_since_midnight'])['tip_amount_normalized'].mean()\n",
    "#merged2013df.groupby('hours_since_midnight')['tip_amount_normalized'].head()\n",
    "ax = fare_df.plot(kind='bar', x='hours_since_midnight', y='fare_amount')\n",
    "ax.set_xlabel(\"Hours since Midnight\")\n",
    "ax.set_ylabel(\"Revenue ($USD)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The taxi companies make the most money in the morning and afternoon rush hours. These occur between 7-8am and 3-5pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medallion_tips = merged2013df.groupby(['medallion'])['tip_amount_normalized'].mean()\n",
    "medallion_tips.plot(kind='hist', alpha=0.5, bins=21)\n",
    "plt.xlim(0,.4)\n",
    "ax.set_xlabel(\"Avg. tip for a medallion\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "print \"Maximum Avg. tip for a Medalion = \", medallion_tips.max()\n",
    "print \"Minimum Avg. tip for a Medalion = \", medallion_tips.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medallion_revenue = merged2013df.groupby(['medallion'])['fare_amount'].sum()\n",
    "ax = medallion_revenue.plot(kind='hist', alpha=0.5, bins=21)\n",
    "#plt.xlim(0,.4)\n",
    "ax.set_xlabel(\"Revenue per Medallion\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "#print \"Maximum Avg. tip for a Medalion = \", medallion_tips.max()\n",
    "#print \"Minimum Avg. tip for a Medalion = \", medallion_tips.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medallion_revenue = merged2013df.groupby(['medallion'])['fare_amount'].mean()\n",
    "medallion_revenue.plot(kind='hist', alpha=0.5, bins=50)\n",
    "ax.set_xlabel(\"Avg. fare for a medallion\")\n",
    "ax.set_ylabel(\"Frequency\") \n",
    "#plt.xlim(0,75)\n",
    "#print \"Maximum Avg. tip for a Medalion = \", medallion_tips.max()\n",
    "#print \"Minimum Avg. tip for a Medalion = \", medallion_tips.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vendor_fares = merged2013df.groupby(['vendor_id'])['fare_amount'].sum()\n",
    "#merged2013df.groupby(['hours_since_midnight'])['tip_amount_normalized'].mean()\n",
    "#merged2013df.groupby('hours_since_midnight')['tip_amount_normalized'].head()\n",
    "ax = vendor_fares.plot(kind='bar', x='vendor_id', y='fare_amount')\n",
    "ax.set_xlabel(\"Vendor ID\")\n",
    "ax.set_ylabel(\"Revenue ($USD)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vendor_tips = merged2013df.groupby(['vendor_id'])['tip_amount_normalized'].mean()\n",
    "ax = vendor_tips.plot(kind='bar', x='vendor_id', y='tip_amount_normalized')\n",
    "ax.set_xlabel(\"Vendor ID\")\n",
    "ax.set_ylabel(\"Average Tip %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "longitude_tip = merged2013df.groupby(['pickup_longitude'])['tip_amount_normalized'].mean()\n",
    "longitude_tip.plot(kind='hist', alpha=0.5, bins=50)\n",
    "ax.set_xlabel(\"Avg. fare for a medallion\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "#plt.xlim(0,.5)\n",
    "#print \"Maximum Avg. tip for a Medalion = \", medallion_tips.max()\n",
    "#print \"Minimum Avg. tip for a Medalion = \", medallion_tips.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latitude_tip = merged2013df.groupby(['pickup_latitude'])['tip_amount_normalized'].mean()\n",
    "latitude_tip.plot(kind='hist', alpha=0.5, bins=50)\n",
    "ax.set_xlabel(\"Latitude of pickup\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "#plt.xlim(0,.5)\n",
    "#print \"Maximum Avg. tip for a Medalion = \", medallion_tips.max()\n",
    "#print \"Minimum Avg. tip for a Medalion = \", medallion_tips.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratecode_tip = merged2013df.groupby(['rate_code_name'])['tip_amount_normalized'].mean()\n",
    "ax = ratecode_tip.plot(kind='bar', alpha=0.5, x='rate_code_name', y='tip_amount_normalized')\n",
    "ax.set_xlabel(\"Rate Code\")\n",
    "ax.set_ylabel(\"Average tip %\")\n",
    "#plt.xlim(0,.5)\n",
    "\n",
    "#print \"Maximum Avg. tip for a Medalion = \", medallion_tips.max()\n",
    "#print \"Minimum Avg. tip for a Medalion = \", medallion_tips.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged2013df[merged2013df['rate_code'] == 3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefan/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:42: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/stefan/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['rate_code',\n",
    "            'passenger_count',\n",
    "            'trip_time_in_secs',\n",
    "            'trip_distance',\n",
    "            'pickup_longitude',\n",
    "            'pickup_latitude',\n",
    "            'dropoff_longitude',\n",
    "            'dropoff_latitude',\n",
    "            'fare_amount',\n",
    "            'surcharge',\n",
    "            'mta_tax',\n",
    "            'tolls_amount',\n",
    "            'secs_since_midnight',\n",
    "            'hours_since_midnight']\n",
    "train_df, test_df = train_test_split(small_crd_df)\n",
    "train_X = train_df[features]\n",
    "train_y = train_df.tip_class\n",
    "test_X = test_df[features]\n",
    "test_y = test_df.tip_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), MLPClassifier(verbose = True))\n",
    "params = dict(mlpclassifier__alpha=10.0 ** -np.arange(1, 7), mlpclassifier__hidden_layer_sizes=np.array([(75,), (50,), (40,25)]))\n",
    "grid_search = GridSearchCV(clf, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search.fit(train_X, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
